{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Making sure satellite algorythms meet people's needs Information from the ground is necessary to design models that meet peoples needs. These materials will guide you through an example of evaluating and improving a satellite index of drought. Client input is necessary for design There are many things that the human or AI engineer does not know about the client's needs. For example, rainfall alone does not determine when a farmer can sow, or needs coverage to start. It is necessary to know what flexibility farmers have in crop types and labor availability to answer this question. Makes products that are better suited to clientelle Improves demand . Farmers who have had input on their products have more ownership and understanding. Reduces complaints. Products are more transparent, and many errors are discovered and addressed before failure happens. Improves accuracy. We have found that farmers themselves nearly universally design better indexes than provided by experts. Provides clientelle with voice and agency","title":"Home"},{"location":"#making-sure-satellite-algorythms-meet-peoples-needs","text":"Information from the ground is necessary to design models that meet peoples needs. These materials will guide you through an example of evaluating and improving a satellite index of drought.","title":"Making sure satellite algorythms meet people's needs"},{"location":"#client-input-is-necessary-for-design","text":"There are many things that the human or AI engineer does not know about the client's needs. For example, rainfall alone does not determine when a farmer can sow, or needs coverage to start. It is necessary to know what flexibility farmers have in crop types and labor availability to answer this question. Makes products that are better suited to clientelle Improves demand . Farmers who have had input on their products have more ownership and understanding. Reduces complaints. Products are more transparent, and many errors are discovered and addressed before failure happens. Improves accuracy. We have found that farmers themselves nearly universally design better indexes than provided by experts. Provides clientelle with voice and agency","title":"Client input is necessary for design"},{"location":"comparisiontable/","text":"Evaluating information and indexes The chart below compares the bad years that the village reported with the years that had low rainfall in the satellite record, during the highlighted times just discussed. Years are listed on the x axis Taller bars are worse years, Grey bars are the farmer reported droughts The Tallest grey bar is the worst year the village remembered The satellite rainfall record is filtered by the farmer reported vulnerability timing The early season sowing (blue), late season flowering (orange), and vegetative de-greening (green) periods are the same colors as before the colored bars represent how bad the satellite rainfall was during those decads in each year There is an additional red bar that represents if any of the satellite metrics (the combined severity) reflected a bad year, which was used to design the insurance index. A red o marks any year where none of the satellite indicators were bad enough to be considered a meaningful deficit. You can explore the agreement in the information Which years did the farmers say were bad that were also represented in the satelite data for the reported seasonal timing? Which farmer bad years were not reflected in the satellite data with that timing? What is the ratio of years with hits vs misses? The answers to those questions are summarized automatically if you scroll to the matching table at the bottom of the page. In the matching table, you can see how much any data source matched another by looking at the rows and colums. For example, you can see that the combined severity agreed with the farmer bad years 50% of the time. But what if we wanted to know the matching of the timing for rainfall vulnerability earlier in the season?","title":"Evaluating information and indexes"},{"location":"comparisiontable/#evaluating-information-and-indexes","text":"The chart below compares the bad years that the village reported with the years that had low rainfall in the satellite record, during the highlighted times just discussed. Years are listed on the x axis Taller bars are worse years, Grey bars are the farmer reported droughts The Tallest grey bar is the worst year the village remembered The satellite rainfall record is filtered by the farmer reported vulnerability timing The early season sowing (blue), late season flowering (orange), and vegetative de-greening (green) periods are the same colors as before the colored bars represent how bad the satellite rainfall was during those decads in each year There is an additional red bar that represents if any of the satellite metrics (the combined severity) reflected a bad year, which was used to design the insurance index. A red o marks any year where none of the satellite indicators were bad enough to be considered a meaningful deficit. You can explore the agreement in the information Which years did the farmers say were bad that were also represented in the satelite data for the reported seasonal timing? Which farmer bad years were not reflected in the satellite data with that timing? What is the ratio of years with hits vs misses? The answers to those questions are summarized automatically if you scroll to the matching table at the bottom of the page. In the matching table, you can see how much any data source matched another by looking at the rows and colums. For example, you can see that the combined severity agreed with the farmer bad years 50% of the time. But what if we wanted to know the matching of the timing for rainfall vulnerability earlier in the season?","title":"Evaluating information and indexes"},{"location":"comparisonexample/","text":"Reported Rainfall timing in Village of Genete (Ethiopia) In the village of Genete, we can perform this crosscheck. We will use the timing of the season in decads, a common form for agronomists. A decad reflects approximately 10 days from the new year, so decad 4 starts Feb 1, Decad 7 starts March 1, Decad 19 July 1, Decad 25 is September 1. The quantitative focus group in Genete said that the key times they were vulnerable to rainfall were during flowering (late July and September) and preparation and planting, beginning in March and continuing into early July. Below you can see the Rainfall climatology for the village, is the average rainfall during the year over their reported cropping cycle. The most vulnerable times of year initially reported are higlighted in blue for the beginning of the year, and orange for the flowering, later in the year. To provide ain dditional verification source, green bar reflects the timing that the vegetation would change color to reflect seasonal end, after the rainfall in the time highlighted in orange had passed, and the landscape had time to respond. There was intense discussion about if the most important start of the season was decad 7 or 18.","title":"Reported Rainfall timing in Village of Genete (Ethiopia)"},{"location":"comparisonexample/#reported-rainfall-timing-in-village-of-genete-ethiopia","text":"In the village of Genete, we can perform this crosscheck. We will use the timing of the season in decads, a common form for agronomists. A decad reflects approximately 10 days from the new year, so decad 4 starts Feb 1, Decad 7 starts March 1, Decad 19 July 1, Decad 25 is September 1. The quantitative focus group in Genete said that the key times they were vulnerable to rainfall were during flowering (late July and September) and preparation and planting, beginning in March and continuing into early July. Below you can see the Rainfall climatology for the village, is the average rainfall during the year over their reported cropping cycle. The most vulnerable times of year initially reported are higlighted in blue for the beginning of the year, and orange for the flowering, later in the year. To provide ain dditional verification source, green bar reflects the timing that the vegetation would change color to reflect seasonal end, after the rainfall in the time highlighted in orange had passed, and the landscape had time to respond. There was intense discussion about if the most important start of the season was decad 7 or 18.","title":"Reported Rainfall timing in Village of Genete (Ethiopia)"},{"location":"concreteinput/","text":"Concrete input In this example we utilize these two questions for concrete, specific input. What specific times of year are you most vulnerable to drought? What were the most severe drought years you have experienced? The drought years are ordered in severity by the community, with 1 being the worst year. For strategies that have been low cost and scalable in effectively framing these questions to communities, you can refer to Project Field Guides","title":"Concrete input"},{"location":"concreteinput/#concrete-input","text":"In this example we utilize these two questions for concrete, specific input. What specific times of year are you most vulnerable to drought? What were the most severe drought years you have experienced? The drought years are ordered in severity by the community, with 1 being the worst year. For strategies that have been low cost and scalable in effectively framing these questions to communities, you can refer to Project Field Guides","title":"Concrete input"},{"location":"crosscheck/","text":"Crosscheck Example For our example, this has proven to be an effective crosscheck using satellite data and focus group input. Check the satellite rainfall data during the times of the season for the lowest rainfall years Compare against the list of years from the focus groups This provides a simultaneous statistical test of the accuracy of focus group seasonal timing reporting focus group drought severity ranking satellite rainfall data If the drought years agree between the satellite data focused on reported seasonal timing and the drought years remembered, then that is a statistical test demonstrating accuracy of all datasets. If the datasets do not agree, we do not know which are inaccurate. But we can explore timing parameters to optimize fit using various statistical and performance metrics.","title":"Crosscheck Example"},{"location":"crosscheck/#crosscheck-example","text":"For our example, this has proven to be an effective crosscheck using satellite data and focus group input. Check the satellite rainfall data during the times of the season for the lowest rainfall years Compare against the list of years from the focus groups This provides a simultaneous statistical test of the accuracy of focus group seasonal timing reporting focus group drought severity ranking satellite rainfall data If the drought years agree between the satellite data focused on reported seasonal timing and the drought years remembered, then that is a statistical test demonstrating accuracy of all datasets. If the datasets do not agree, we do not know which are inaccurate. But we can explore timing parameters to optimize fit using various statistical and performance metrics.","title":"Crosscheck Example"},{"location":"key/","text":"Unlocking large scale feedback Information from large scale co-design can include a lot of noise. It is necessary to have a strategy that can filter the truth from the noise. Key components We need two components for this approach to quantitative client codesign Concrete specific input. Open discussion is important in codesign, but for this part, it is critical to obtain engineering quality quantitative input. In the past key design choices have been incorrect because the co-design was not adequately quantitative. Crosschecking verification. It is important to have an evaluation mechanism embedded at the heart of the process to identify solutions and filter out noise. Real world performance This strategy has been successful at large scales for low cost, in thousands of villages across dozens of countries. For example, the government of Zambia performed this exercise across the entire country, with most of the site visits completed within a few weeks. We will work through an example for a satellite model of drought in Ethiopia, used for an insurance index.","title":"Key"},{"location":"key/#unlocking-large-scale-feedback","text":"Information from large scale co-design can include a lot of noise. It is necessary to have a strategy that can filter the truth from the noise.","title":"Unlocking large scale feedback"},{"location":"key/#key-components","text":"We need two components for this approach to quantitative client codesign Concrete specific input. Open discussion is important in codesign, but for this part, it is critical to obtain engineering quality quantitative input. In the past key design choices have been incorrect because the co-design was not adequately quantitative. Crosschecking verification. It is important to have an evaluation mechanism embedded at the heart of the process to identify solutions and filter out noise.","title":"Key components"},{"location":"key/#real-world-performance","text":"This strategy has been successful at large scales for low cost, in thousands of villages across dozens of countries. For example, the government of Zambia performed this exercise across the entire country, with most of the site visits completed within a few weeks. We will work through an example for a satellite model of drought in Ethiopia, used for an insurance index.","title":"Real world performance"},{"location":"noki/","text":"Phone feedback, games, and contests One way to obtain fast feedback is to utilize two way phone text or recorded voice communications. We have found that providing incentives for accuracy, such as awards, or games can be important. However, these kinds of communications can yield noisy data, often with inaccurate or strategic responses. Research has found that two strategies can be effective in filtering information Incentivize accuracy: provide a prize or honor for being more accurate Verification questions: ask questions we know the answer to, and focus on responses of people who got those questions \"right\" Using the flexible NOKI platform in the DESDR toolkit we could set up this contest to quickly incentivize cogeneration feedback. We can frame the question as a contest--how well could a farmer playing from a phone represent the preferences of their community over which kind of year is more important, 1994, or 2002. The player could win (and perhaps get a prize) if they can guess what others would say. We also know that 2009 was consistently bad, and 2010 was consistently good, so we could also ask people to compare those years so to help filter results. To experience an example of a phone codesign implimentation that you might use, text or whatsapp genete to +1 (646) 217-0881 These tools are flexible for different cogeneration challenges, and they are open source. What would you use these tools and approaches for?","title":"Phone feedback, games, and contests"},{"location":"noki/#phone-feedback-games-and-contests","text":"One way to obtain fast feedback is to utilize two way phone text or recorded voice communications. We have found that providing incentives for accuracy, such as awards, or games can be important. However, these kinds of communications can yield noisy data, often with inaccurate or strategic responses. Research has found that two strategies can be effective in filtering information Incentivize accuracy: provide a prize or honor for being more accurate Verification questions: ask questions we know the answer to, and focus on responses of people who got those questions \"right\" Using the flexible NOKI platform in the DESDR toolkit we could set up this contest to quickly incentivize cogeneration feedback. We can frame the question as a contest--how well could a farmer playing from a phone represent the preferences of their community over which kind of year is more important, 1994, or 2002. The player could win (and perhaps get a prize) if they can guess what others would say. We also know that 2009 was consistently bad, and 2010 was consistently good, so we could also ask people to compare those years so to help filter results. To experience an example of a phone codesign implimentation that you might use, text or whatsapp genete to +1 (646) 217-0881 These tools are flexible for different cogeneration challenges, and they are open source. What would you use these tools and approaches for?","title":"Phone feedback, games, and contests"},{"location":"slideyouself/","text":"Design improvement You can explore the farmers debate of if rainfall starting around decad 7 is more related to vulnerability than rainfall starting in decad 18. The below is an interactive tool to evaluate and co-design indexes. It is part of our public domain DESDR open toolkit. It has all of the tables and figures we have just worked through but it also has controls Click on the tool below, then drag the sliders for the rainfall early timing to be more focused on the rainfall starting around decad 7 and extending 5-10 decads. Do you see changes in matching? Do you have a new timing to verify with farmers?","title":"Design improvement"},{"location":"slideyouself/#design-improvement","text":"You can explore the farmers debate of if rainfall starting around decad 7 is more related to vulnerability than rainfall starting in decad 18. The below is an interactive tool to evaluate and co-design indexes. It is part of our public domain DESDR open toolkit. It has all of the tables and figures we have just worked through but it also has controls Click on the tool below, then drag the sliders for the rainfall early timing to be more focused on the rainfall starting around decad 7 and extending 5-10 decads. Do you see changes in matching? Do you have a new timing to verify with farmers?","title":"Design improvement"},{"location":"toughchoices/","text":"Not enough information Although years like 2009 is consistently bad, and 2010 is consistently good... Using the design and evaluation tools we can see that there are multiple options with the same level of high agreement. For example. The very early time period from decads 6-17: * 88% agreement * Reflects the challenges in 1984 * Doesnt reflect 2002, and has very small anomalies (potentially small insurance payouts) in years like 1994 The slightly later time period from decads 10-17: * 88% agreement * Reflects 2002 and 1994 * Doesnt reflect 1984 This is because the seasonal timing of rainfall in 2002 was later than that of 1984. Without client cogeneration inside of the design loop, we do not have an adequate information to make this choice. If only we could ask the farmers if they would prefer to have coverage that focused on rainfall as early in the season as the deficit of 1984 or if they were able to shift their practices in response to the rainfall timing to want coverage that focused on the later timing of 2002. Next we will explore a cogeneration tool that can address that challenge.","title":"Not enough information"},{"location":"toughchoices/#not-enough-information","text":"Although years like 2009 is consistently bad, and 2010 is consistently good... Using the design and evaluation tools we can see that there are multiple options with the same level of high agreement. For example. The very early time period from decads 6-17: * 88% agreement * Reflects the challenges in 1984 * Doesnt reflect 2002, and has very small anomalies (potentially small insurance payouts) in years like 1994 The slightly later time period from decads 10-17: * 88% agreement * Reflects 2002 and 1994 * Doesnt reflect 1984 This is because the seasonal timing of rainfall in 2002 was later than that of 1984. Without client cogeneration inside of the design loop, we do not have an adequate information to make this choice. If only we could ask the farmers if they would prefer to have coverage that focused on rainfall as early in the season as the deficit of 1984 or if they were able to shift their practices in response to the rainfall timing to want coverage that focused on the later timing of 2002. Next we will explore a cogeneration tool that can address that challenge.","title":"Not enough information"}]}